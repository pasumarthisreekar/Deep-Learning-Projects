{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNFmGVHdi5JuoP0jQJ6rkDg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreekar-pasumarthi/Deep-Learning-Projects/blob/master/glass_stackedautoclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3u_h4R7Y1st",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stacked autoencoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nPPx0nyZCeJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "62564416-879a-41ec-ae72-91ef44ae47c2"
      },
      "source": [
        "df_train = pd.read_csv('https://raw.githubusercontent.com/sreekar-pasumarthi/Deep-Learning-Projects/master/glass/glass.csv')\n",
        "print(f'The train set contain {df_train.shape[0]} examples')\n",
        "print(f'The train set contain {df_train.shape[1]} features')\n",
        "df_train.head()#to select first n rows"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The train set contain 214 examples\n",
            "The train set contain 10 features\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RI</th>\n",
              "      <th>Na</th>\n",
              "      <th>Mg</th>\n",
              "      <th>Al</th>\n",
              "      <th>Si</th>\n",
              "      <th>K</th>\n",
              "      <th>Ca</th>\n",
              "      <th>Ba</th>\n",
              "      <th>Fe</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.52101</td>\n",
              "      <td>13.64</td>\n",
              "      <td>4.49</td>\n",
              "      <td>1.10</td>\n",
              "      <td>71.78</td>\n",
              "      <td>0.06</td>\n",
              "      <td>8.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.51761</td>\n",
              "      <td>13.89</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.36</td>\n",
              "      <td>72.73</td>\n",
              "      <td>0.48</td>\n",
              "      <td>7.83</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.51618</td>\n",
              "      <td>13.53</td>\n",
              "      <td>3.55</td>\n",
              "      <td>1.54</td>\n",
              "      <td>72.99</td>\n",
              "      <td>0.39</td>\n",
              "      <td>7.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.51766</td>\n",
              "      <td>13.21</td>\n",
              "      <td>3.69</td>\n",
              "      <td>1.29</td>\n",
              "      <td>72.61</td>\n",
              "      <td>0.57</td>\n",
              "      <td>8.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.51742</td>\n",
              "      <td>13.27</td>\n",
              "      <td>3.62</td>\n",
              "      <td>1.24</td>\n",
              "      <td>73.08</td>\n",
              "      <td>0.55</td>\n",
              "      <td>8.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
              "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
              "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
              "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
              "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
              "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vPSjl9UZDIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df_train.drop('Type', axis = 1)#drops the column type from the dataframe\n",
        "y_train = df_train['Type']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aWuI1oBZFEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiNHGn4IZHZ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "dd20290b-8f32-4999-b955-0eddeccf3ef2"
      },
      "source": [
        "X_train=((X_train-X_train.mean())/(X_train.max()-X_train.min()))\n",
        "X_train.describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RI</th>\n",
              "      <th>Na</th>\n",
              "      <th>Mg</th>\n",
              "      <th>Al</th>\n",
              "      <th>Si</th>\n",
              "      <th>K</th>\n",
              "      <th>Ca</th>\n",
              "      <th>Ba</th>\n",
              "      <th>Fe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.140000e+02</td>\n",
              "      <td>2.140000e+02</td>\n",
              "      <td>2.140000e+02</td>\n",
              "      <td>2.140000e+02</td>\n",
              "      <td>2.140000e+02</td>\n",
              "      <td>2.140000e+02</td>\n",
              "      <td>2.140000e+02</td>\n",
              "      <td>2.140000e+02</td>\n",
              "      <td>2.140000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.542954e-14</td>\n",
              "      <td>-5.429847e-16</td>\n",
              "      <td>-2.116687e-16</td>\n",
              "      <td>-9.480993e-17</td>\n",
              "      <td>1.303474e-16</td>\n",
              "      <td>3.086835e-17</td>\n",
              "      <td>-4.302763e-17</td>\n",
              "      <td>1.188042e-16</td>\n",
              "      <td>1.530448e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.333127e-01</td>\n",
              "      <td>1.227975e-01</td>\n",
              "      <td>3.212490e-01</td>\n",
              "      <td>1.555357e-01</td>\n",
              "      <td>1.383117e-01</td>\n",
              "      <td>1.050228e-01</td>\n",
              "      <td>1.322633e-01</td>\n",
              "      <td>1.578474e-01</td>\n",
              "      <td>1.910563e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-3.167437e-01</td>\n",
              "      <td>-4.026843e-01</td>\n",
              "      <td>-5.978915e-01</td>\n",
              "      <td>-3.597840e-01</td>\n",
              "      <td>-5.073097e-01</td>\n",
              "      <td>-8.004124e-02</td>\n",
              "      <td>-3.277846e-01</td>\n",
              "      <td>-5.557039e-02</td>\n",
              "      <td>-1.117830e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-8.090081e-02</td>\n",
              "      <td>-7.524067e-02</td>\n",
              "      <td>-1.268447e-01</td>\n",
              "      <td>-7.941014e-02</td>\n",
              "      <td>-6.623832e-02</td>\n",
              "      <td>-6.031499e-02</td>\n",
              "      <td>-6.663221e-02</td>\n",
              "      <td>-5.557039e-02</td>\n",
              "      <td>-1.117830e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-3.008870e-02</td>\n",
              "      <td>-1.621812e-02</td>\n",
              "      <td>1.771642e-01</td>\n",
              "      <td>-2.645064e-02</td>\n",
              "      <td>2.483311e-02</td>\n",
              "      <td>9.330745e-03</td>\n",
              "      <td>-3.317496e-02</td>\n",
              "      <td>-5.557039e-02</td>\n",
              "      <td>-1.117830e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.477083e-02</td>\n",
              "      <td>6.272925e-02</td>\n",
              "      <td>2.038903e-01</td>\n",
              "      <td>5.766151e-02</td>\n",
              "      <td>7.795811e-02</td>\n",
              "      <td>1.818743e-02</td>\n",
              "      <td>2.003136e-02</td>\n",
              "      <td>-5.557039e-02</td>\n",
              "      <td>8.429540e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6.832563e-01</td>\n",
              "      <td>5.973157e-01</td>\n",
              "      <td>4.021085e-01</td>\n",
              "      <td>6.402160e-01</td>\n",
              "      <td>4.926903e-01</td>\n",
              "      <td>9.199588e-01</td>\n",
              "      <td>6.722154e-01</td>\n",
              "      <td>9.444296e-01</td>\n",
              "      <td>8.882170e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 RI            Na  ...            Ba            Fe\n",
              "count  2.140000e+02  2.140000e+02  ...  2.140000e+02  2.140000e+02\n",
              "mean   3.542954e-14 -5.429847e-16  ...  1.188042e-16  1.530448e-17\n",
              "std    1.333127e-01  1.227975e-01  ...  1.578474e-01  1.910563e-01\n",
              "min   -3.167437e-01 -4.026843e-01  ... -5.557039e-02 -1.117830e-01\n",
              "25%   -8.090081e-02 -7.524067e-02  ... -5.557039e-02 -1.117830e-01\n",
              "50%   -3.008870e-02 -1.621812e-02  ... -5.557039e-02 -1.117830e-01\n",
              "75%    3.477083e-02  6.272925e-02  ... -5.557039e-02  8.429540e-02\n",
              "max    6.832563e-01  5.973157e-01  ...  9.444296e-01  8.882170e-01\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF5WCi6oZOd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThTprlRVZPSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY6SYm5yZR0P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "f2a3f3e8-c940-47d7-ea87-a6bbbc34ef73"
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "input_img = Input(shape=(9,))\n",
        "activation_fn= 'tanh'\n",
        "epochs=200\n",
        "batch_size=1\n",
        "shuffle=True\n",
        "\n",
        "encoded = Dense(5, activation= activation_fn)(input_img)\n",
        "decoded = Dense(9, activation='tanh')(encoded)\n",
        "\n",
        "#9->5->9\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 9)                 0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 50        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 9)                 54        \n",
            "=================================================================\n",
            "Total params: 104\n",
            "Trainable params: 104\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSSgRG84Z_fR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
        "autoencoder.fit(X_train, X_train,epochs=epochs,batch_size=batch_size,shuffle=shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG-ojf-qbb2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d5ce939-4b93-4ea2-db42-348a7598dd01"
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "batch_size = 1\n",
        "epochs = 100\n",
        "\n",
        "# Layer-wise pretraining\n",
        "encoders = []\n",
        "nb_layers = [9, 5, 4]\n",
        "X_train_tmp = np.copy(X_train)\n",
        "for i, (n_in, n_out) in enumerate(zip(nb_layers[:-1], nb_layers[1:]), start=1):\n",
        "    print('Training the layer {}: Input {} -> Output {}'.format(i, n_in, n_out))\n",
        "    # Create AE and training\n",
        "    input_img = Input(shape=(n_in,))\n",
        "    encoded = Dense(n_out, activation='sigmoid')(input_img)\n",
        "    decoded = Dense(n_in, activation='sigmoid')(encoded)\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    encoder=Model(input_img,encoded)\n",
        "    autoencoder.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
        "    autoencoder.fit(X_train_tmp, X_train_tmp, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "    # Store trained weights and update training data\n",
        "    encoders.append(autoencoder.layers[0].get_weights())\n",
        "    X_train_tmp = encoder.predict(X_train_tmp)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the layer 1: Input 9 -> Output 5\n",
            "Epoch 1/100\n",
            "214/214 [==============================] - 0s 932us/step - loss: 0.2102\n",
            "Epoch 2/100\n",
            "214/214 [==============================] - 0s 812us/step - loss: 0.1083\n",
            "Epoch 3/100\n",
            "214/214 [==============================] - 0s 813us/step - loss: 0.0583\n",
            "Epoch 4/100\n",
            "214/214 [==============================] - 0s 777us/step - loss: 0.0397\n",
            "Epoch 5/100\n",
            "214/214 [==============================] - 0s 823us/step - loss: 0.0335\n",
            "Epoch 6/100\n",
            "214/214 [==============================] - 0s 812us/step - loss: 0.0314\n",
            "Epoch 7/100\n",
            "214/214 [==============================] - 0s 846us/step - loss: 0.0306\n",
            "Epoch 8/100\n",
            "214/214 [==============================] - 0s 796us/step - loss: 0.0302\n",
            "Epoch 9/100\n",
            "214/214 [==============================] - 0s 800us/step - loss: 0.0300\n",
            "Epoch 10/100\n",
            "214/214 [==============================] - 0s 809us/step - loss: 0.0298\n",
            "Epoch 11/100\n",
            "214/214 [==============================] - 0s 783us/step - loss: 0.0297\n",
            "Epoch 12/100\n",
            "214/214 [==============================] - 0s 768us/step - loss: 0.0296\n",
            "Epoch 13/100\n",
            "214/214 [==============================] - 0s 794us/step - loss: 0.0295\n",
            "Epoch 14/100\n",
            "214/214 [==============================] - 0s 831us/step - loss: 0.0294\n",
            "Epoch 15/100\n",
            "214/214 [==============================] - 0s 846us/step - loss: 0.0293\n",
            "Epoch 16/100\n",
            "214/214 [==============================] - 0s 778us/step - loss: 0.0292\n",
            "Epoch 17/100\n",
            "214/214 [==============================] - 0s 781us/step - loss: 0.0290\n",
            "Epoch 18/100\n",
            "214/214 [==============================] - 0s 811us/step - loss: 0.0289\n",
            "Epoch 19/100\n",
            "214/214 [==============================] - 0s 810us/step - loss: 0.0287\n",
            "Epoch 20/100\n",
            "214/214 [==============================] - 0s 795us/step - loss: 0.0285\n",
            "Epoch 21/100\n",
            "214/214 [==============================] - 0s 789us/step - loss: 0.0283\n",
            "Epoch 22/100\n",
            "214/214 [==============================] - 0s 791us/step - loss: 0.0281\n",
            "Epoch 23/100\n",
            "214/214 [==============================] - 0s 774us/step - loss: 0.0279\n",
            "Epoch 24/100\n",
            "214/214 [==============================] - 0s 803us/step - loss: 0.0277\n",
            "Epoch 25/100\n",
            "214/214 [==============================] - 0s 799us/step - loss: 0.0275\n",
            "Epoch 26/100\n",
            "214/214 [==============================] - 0s 811us/step - loss: 0.0274\n",
            "Epoch 27/100\n",
            "214/214 [==============================] - 0s 762us/step - loss: 0.0272\n",
            "Epoch 28/100\n",
            "214/214 [==============================] - 0s 775us/step - loss: 0.0271\n",
            "Epoch 29/100\n",
            "214/214 [==============================] - 0s 815us/step - loss: 0.0269\n",
            "Epoch 30/100\n",
            "214/214 [==============================] - 0s 778us/step - loss: 0.0268\n",
            "Epoch 31/100\n",
            "214/214 [==============================] - 0s 808us/step - loss: 0.0267\n",
            "Epoch 32/100\n",
            "214/214 [==============================] - 0s 811us/step - loss: 0.0266\n",
            "Epoch 33/100\n",
            "214/214 [==============================] - 0s 894us/step - loss: 0.0265\n",
            "Epoch 34/100\n",
            "214/214 [==============================] - 0s 783us/step - loss: 0.0264\n",
            "Epoch 35/100\n",
            "214/214 [==============================] - 0s 781us/step - loss: 0.0263\n",
            "Epoch 36/100\n",
            "214/214 [==============================] - 0s 777us/step - loss: 0.0262\n",
            "Epoch 37/100\n",
            "214/214 [==============================] - 0s 831us/step - loss: 0.0261\n",
            "Epoch 38/100\n",
            "214/214 [==============================] - 0s 845us/step - loss: 0.0260\n",
            "Epoch 39/100\n",
            "214/214 [==============================] - 0s 784us/step - loss: 0.0260\n",
            "Epoch 40/100\n",
            "214/214 [==============================] - 0s 799us/step - loss: 0.0259\n",
            "Epoch 41/100\n",
            "214/214 [==============================] - 0s 811us/step - loss: 0.0258\n",
            "Epoch 42/100\n",
            "214/214 [==============================] - 0s 846us/step - loss: 0.0257\n",
            "Epoch 43/100\n",
            "214/214 [==============================] - 0s 809us/step - loss: 0.0256\n",
            "Epoch 44/100\n",
            "214/214 [==============================] - 0s 778us/step - loss: 0.0255\n",
            "Epoch 45/100\n",
            "214/214 [==============================] - 0s 779us/step - loss: 0.0254\n",
            "Epoch 46/100\n",
            "214/214 [==============================] - 0s 799us/step - loss: 0.0253\n",
            "Epoch 47/100\n",
            "214/214 [==============================] - 0s 817us/step - loss: 0.0252\n",
            "Epoch 48/100\n",
            "214/214 [==============================] - 0s 790us/step - loss: 0.0251\n",
            "Epoch 49/100\n",
            "214/214 [==============================] - 0s 818us/step - loss: 0.0250\n",
            "Epoch 50/100\n",
            "214/214 [==============================] - 0s 789us/step - loss: 0.0249\n",
            "Epoch 51/100\n",
            "214/214 [==============================] - 0s 784us/step - loss: 0.0248\n",
            "Epoch 52/100\n",
            "214/214 [==============================] - 0s 786us/step - loss: 0.0247\n",
            "Epoch 53/100\n",
            "214/214 [==============================] - 0s 767us/step - loss: 0.0246\n",
            "Epoch 54/100\n",
            "214/214 [==============================] - 0s 821us/step - loss: 0.0245\n",
            "Epoch 55/100\n",
            "214/214 [==============================] - 0s 821us/step - loss: 0.0245\n",
            "Epoch 56/100\n",
            "214/214 [==============================] - 0s 779us/step - loss: 0.0244\n",
            "Epoch 57/100\n",
            "214/214 [==============================] - 0s 772us/step - loss: 0.0243\n",
            "Epoch 58/100\n",
            "214/214 [==============================] - 0s 777us/step - loss: 0.0242\n",
            "Epoch 59/100\n",
            "214/214 [==============================] - 0s 834us/step - loss: 0.0242\n",
            "Epoch 60/100\n",
            "214/214 [==============================] - 0s 805us/step - loss: 0.0241\n",
            "Epoch 61/100\n",
            "214/214 [==============================] - 0s 801us/step - loss: 0.0241\n",
            "Epoch 62/100\n",
            "214/214 [==============================] - 0s 781us/step - loss: 0.0240\n",
            "Epoch 63/100\n",
            "214/214 [==============================] - 0s 776us/step - loss: 0.0240\n",
            "Epoch 64/100\n",
            "214/214 [==============================] - 0s 793us/step - loss: 0.0240\n",
            "Epoch 65/100\n",
            "214/214 [==============================] - 0s 806us/step - loss: 0.0240\n",
            "Epoch 66/100\n",
            "214/214 [==============================] - 0s 842us/step - loss: 0.0239\n",
            "Epoch 67/100\n",
            "214/214 [==============================] - 0s 788us/step - loss: 0.0239\n",
            "Epoch 68/100\n",
            "214/214 [==============================] - 0s 794us/step - loss: 0.0239\n",
            "Epoch 69/100\n",
            "214/214 [==============================] - 0s 822us/step - loss: 0.0239\n",
            "Epoch 70/100\n",
            "214/214 [==============================] - 0s 779us/step - loss: 0.0239\n",
            "Epoch 71/100\n",
            "214/214 [==============================] - 0s 779us/step - loss: 0.0239\n",
            "Epoch 72/100\n",
            "214/214 [==============================] - 0s 791us/step - loss: 0.0239\n",
            "Epoch 73/100\n",
            "214/214 [==============================] - 0s 785us/step - loss: 0.0239\n",
            "Epoch 74/100\n",
            "214/214 [==============================] - 0s 778us/step - loss: 0.0239\n",
            "Epoch 75/100\n",
            "214/214 [==============================] - 0s 790us/step - loss: 0.0239\n",
            "Epoch 76/100\n",
            "214/214 [==============================] - 0s 820us/step - loss: 0.0239\n",
            "Epoch 77/100\n",
            "214/214 [==============================] - 0s 832us/step - loss: 0.0239\n",
            "Epoch 78/100\n",
            "214/214 [==============================] - 0s 802us/step - loss: 0.0238\n",
            "Epoch 79/100\n",
            "214/214 [==============================] - 0s 833us/step - loss: 0.0238\n",
            "Epoch 80/100\n",
            "214/214 [==============================] - 0s 773us/step - loss: 0.0238\n",
            "Epoch 81/100\n",
            "214/214 [==============================] - 0s 783us/step - loss: 0.0238\n",
            "Epoch 82/100\n",
            "214/214 [==============================] - 0s 765us/step - loss: 0.0238\n",
            "Epoch 83/100\n",
            "214/214 [==============================] - 0s 758us/step - loss: 0.0238\n",
            "Epoch 84/100\n",
            "214/214 [==============================] - 0s 825us/step - loss: 0.0238\n",
            "Epoch 85/100\n",
            "214/214 [==============================] - 0s 785us/step - loss: 0.0238\n",
            "Epoch 86/100\n",
            "214/214 [==============================] - 0s 794us/step - loss: 0.0238\n",
            "Epoch 87/100\n",
            "214/214 [==============================] - 0s 773us/step - loss: 0.0238\n",
            "Epoch 88/100\n",
            "214/214 [==============================] - 0s 784us/step - loss: 0.0238\n",
            "Epoch 89/100\n",
            "214/214 [==============================] - 0s 774us/step - loss: 0.0238\n",
            "Epoch 90/100\n",
            "214/214 [==============================] - 0s 795us/step - loss: 0.0238\n",
            "Epoch 91/100\n",
            "214/214 [==============================] - 0s 792us/step - loss: 0.0238\n",
            "Epoch 92/100\n",
            "214/214 [==============================] - 0s 792us/step - loss: 0.0238\n",
            "Epoch 93/100\n",
            "214/214 [==============================] - 0s 786us/step - loss: 0.0238\n",
            "Epoch 94/100\n",
            "214/214 [==============================] - 0s 785us/step - loss: 0.0238\n",
            "Epoch 95/100\n",
            "214/214 [==============================] - 0s 795us/step - loss: 0.0238\n",
            "Epoch 96/100\n",
            "214/214 [==============================] - 0s 835us/step - loss: 0.0238\n",
            "Epoch 97/100\n",
            "214/214 [==============================] - 0s 780us/step - loss: 0.0238\n",
            "Epoch 98/100\n",
            "214/214 [==============================] - 0s 792us/step - loss: 0.0238\n",
            "Epoch 99/100\n",
            "214/214 [==============================] - 0s 874us/step - loss: 0.0238\n",
            "Epoch 100/100\n",
            "214/214 [==============================] - 0s 795us/step - loss: 0.0238\n",
            "Training the layer 2: Input 5 -> Output 4\n",
            "Epoch 1/100\n",
            "214/214 [==============================] - 0s 923us/step - loss: 0.0924\n",
            "Epoch 2/100\n",
            "214/214 [==============================] - 0s 748us/step - loss: 0.0828\n",
            "Epoch 3/100\n",
            "214/214 [==============================] - 0s 752us/step - loss: 0.0794\n",
            "Epoch 4/100\n",
            "214/214 [==============================] - 0s 786us/step - loss: 0.0774\n",
            "Epoch 5/100\n",
            "214/214 [==============================] - 0s 747us/step - loss: 0.0755\n",
            "Epoch 6/100\n",
            "214/214 [==============================] - 0s 785us/step - loss: 0.0733\n",
            "Epoch 7/100\n",
            "214/214 [==============================] - 0s 780us/step - loss: 0.0709\n",
            "Epoch 8/100\n",
            "214/214 [==============================] - 0s 766us/step - loss: 0.0681\n",
            "Epoch 9/100\n",
            "214/214 [==============================] - 0s 774us/step - loss: 0.0649\n",
            "Epoch 10/100\n",
            "214/214 [==============================] - 0s 773us/step - loss: 0.0616\n",
            "Epoch 11/100\n",
            "214/214 [==============================] - 0s 836us/step - loss: 0.0580\n",
            "Epoch 12/100\n",
            "214/214 [==============================] - 0s 809us/step - loss: 0.0543\n",
            "Epoch 13/100\n",
            "214/214 [==============================] - 0s 773us/step - loss: 0.0505\n",
            "Epoch 14/100\n",
            "214/214 [==============================] - 0s 808us/step - loss: 0.0469\n",
            "Epoch 15/100\n",
            "214/214 [==============================] - 0s 826us/step - loss: 0.0432\n",
            "Epoch 16/100\n",
            "214/214 [==============================] - 0s 786us/step - loss: 0.0398\n",
            "Epoch 17/100\n",
            "214/214 [==============================] - 0s 776us/step - loss: 0.0365\n",
            "Epoch 18/100\n",
            "214/214 [==============================] - 0s 797us/step - loss: 0.0335\n",
            "Epoch 19/100\n",
            "214/214 [==============================] - 0s 771us/step - loss: 0.0307\n",
            "Epoch 20/100\n",
            "214/214 [==============================] - 0s 787us/step - loss: 0.0281\n",
            "Epoch 21/100\n",
            "214/214 [==============================] - 0s 770us/step - loss: 0.0258\n",
            "Epoch 22/100\n",
            "214/214 [==============================] - 0s 775us/step - loss: 0.0236\n",
            "Epoch 23/100\n",
            "214/214 [==============================] - 0s 774us/step - loss: 0.0216\n",
            "Epoch 24/100\n",
            "214/214 [==============================] - 0s 835us/step - loss: 0.0196\n",
            "Epoch 25/100\n",
            "214/214 [==============================] - 0s 778us/step - loss: 0.0178\n",
            "Epoch 26/100\n",
            "214/214 [==============================] - 0s 770us/step - loss: 0.0161\n",
            "Epoch 27/100\n",
            "214/214 [==============================] - 0s 768us/step - loss: 0.0144\n",
            "Epoch 28/100\n",
            "214/214 [==============================] - 0s 776us/step - loss: 0.0129\n",
            "Epoch 29/100\n",
            "214/214 [==============================] - 0s 777us/step - loss: 0.0114\n",
            "Epoch 30/100\n",
            "214/214 [==============================] - 0s 843us/step - loss: 0.0101\n",
            "Epoch 31/100\n",
            "214/214 [==============================] - 0s 763us/step - loss: 0.0089\n",
            "Epoch 32/100\n",
            "214/214 [==============================] - 0s 835us/step - loss: 0.0078\n",
            "Epoch 33/100\n",
            "214/214 [==============================] - 0s 824us/step - loss: 0.0068\n",
            "Epoch 34/100\n",
            "214/214 [==============================] - 0s 803us/step - loss: 0.0059\n",
            "Epoch 35/100\n",
            "214/214 [==============================] - 0s 815us/step - loss: 0.0052\n",
            "Epoch 36/100\n",
            "214/214 [==============================] - 0s 858us/step - loss: 0.0045\n",
            "Epoch 37/100\n",
            "214/214 [==============================] - 0s 828us/step - loss: 0.0040\n",
            "Epoch 38/100\n",
            "214/214 [==============================] - 0s 841us/step - loss: 0.0035\n",
            "Epoch 39/100\n",
            "214/214 [==============================] - 0s 774us/step - loss: 0.0031\n",
            "Epoch 40/100\n",
            "214/214 [==============================] - 0s 815us/step - loss: 0.0028\n",
            "Epoch 41/100\n",
            "214/214 [==============================] - 0s 773us/step - loss: 0.0026\n",
            "Epoch 42/100\n",
            "214/214 [==============================] - 0s 790us/step - loss: 0.0024\n",
            "Epoch 43/100\n",
            "214/214 [==============================] - 0s 780us/step - loss: 0.0022\n",
            "Epoch 44/100\n",
            "214/214 [==============================] - 0s 784us/step - loss: 0.0021\n",
            "Epoch 45/100\n",
            "214/214 [==============================] - 0s 809us/step - loss: 0.0020\n",
            "Epoch 46/100\n",
            "214/214 [==============================] - 0s 779us/step - loss: 0.0019\n",
            "Epoch 47/100\n",
            "214/214 [==============================] - 0s 783us/step - loss: 0.0018\n",
            "Epoch 48/100\n",
            "214/214 [==============================] - 0s 840us/step - loss: 0.0018\n",
            "Epoch 49/100\n",
            "214/214 [==============================] - 0s 776us/step - loss: 0.0017\n",
            "Epoch 50/100\n",
            "214/214 [==============================] - 0s 772us/step - loss: 0.0017\n",
            "Epoch 51/100\n",
            "214/214 [==============================] - 0s 775us/step - loss: 0.0017\n",
            "Epoch 52/100\n",
            "214/214 [==============================] - 0s 790us/step - loss: 0.0016\n",
            "Epoch 53/100\n",
            "214/214 [==============================] - 0s 826us/step - loss: 0.0016\n",
            "Epoch 54/100\n",
            "214/214 [==============================] - 0s 803us/step - loss: 0.0016\n",
            "Epoch 55/100\n",
            "214/214 [==============================] - 0s 771us/step - loss: 0.0015\n",
            "Epoch 56/100\n",
            "214/214 [==============================] - 0s 797us/step - loss: 0.0015\n",
            "Epoch 57/100\n",
            "214/214 [==============================] - 0s 779us/step - loss: 0.0015\n",
            "Epoch 58/100\n",
            "214/214 [==============================] - 0s 775us/step - loss: 0.0015\n",
            "Epoch 59/100\n",
            "214/214 [==============================] - 0s 820us/step - loss: 0.0015\n",
            "Epoch 60/100\n",
            "214/214 [==============================] - 0s 842us/step - loss: 0.0014\n",
            "Epoch 61/100\n",
            "214/214 [==============================] - 0s 791us/step - loss: 0.0014\n",
            "Epoch 62/100\n",
            "214/214 [==============================] - 0s 771us/step - loss: 0.0014\n",
            "Epoch 63/100\n",
            "214/214 [==============================] - 0s 770us/step - loss: 0.0014\n",
            "Epoch 64/100\n",
            "214/214 [==============================] - 0s 835us/step - loss: 0.0014\n",
            "Epoch 65/100\n",
            "214/214 [==============================] - 0s 798us/step - loss: 0.0014\n",
            "Epoch 66/100\n",
            "214/214 [==============================] - 0s 783us/step - loss: 0.0014\n",
            "Epoch 67/100\n",
            "214/214 [==============================] - 0s 771us/step - loss: 0.0014\n",
            "Epoch 68/100\n",
            "214/214 [==============================] - 0s 774us/step - loss: 0.0014\n",
            "Epoch 69/100\n",
            "214/214 [==============================] - 0s 779us/step - loss: 0.0014\n",
            "Epoch 70/100\n",
            "214/214 [==============================] - 0s 797us/step - loss: 0.0014\n",
            "Epoch 71/100\n",
            "214/214 [==============================] - 0s 811us/step - loss: 0.0014\n",
            "Epoch 72/100\n",
            "214/214 [==============================] - 0s 768us/step - loss: 0.0013\n",
            "Epoch 73/100\n",
            "214/214 [==============================] - 0s 774us/step - loss: 0.0013\n",
            "Epoch 74/100\n",
            "214/214 [==============================] - 0s 773us/step - loss: 0.0013\n",
            "Epoch 75/100\n",
            "214/214 [==============================] - 0s 760us/step - loss: 0.0013\n",
            "Epoch 76/100\n",
            "214/214 [==============================] - 0s 766us/step - loss: 0.0013\n",
            "Epoch 77/100\n",
            "214/214 [==============================] - 0s 954us/step - loss: 0.0013\n",
            "Epoch 78/100\n",
            "214/214 [==============================] - 0s 771us/step - loss: 0.0013\n",
            "Epoch 79/100\n",
            "214/214 [==============================] - 0s 773us/step - loss: 0.0013\n",
            "Epoch 80/100\n",
            "214/214 [==============================] - 0s 778us/step - loss: 0.0013\n",
            "Epoch 81/100\n",
            "214/214 [==============================] - 0s 779us/step - loss: 0.0013\n",
            "Epoch 82/100\n",
            "214/214 [==============================] - 0s 778us/step - loss: 0.0013\n",
            "Epoch 83/100\n",
            "214/214 [==============================] - 0s 820us/step - loss: 0.0013\n",
            "Epoch 84/100\n",
            "214/214 [==============================] - 0s 832us/step - loss: 0.0013\n",
            "Epoch 85/100\n",
            "214/214 [==============================] - 0s 798us/step - loss: 0.0013\n",
            "Epoch 86/100\n",
            "214/214 [==============================] - 0s 776us/step - loss: 0.0013\n",
            "Epoch 87/100\n",
            "214/214 [==============================] - 0s 785us/step - loss: 0.0013\n",
            "Epoch 88/100\n",
            "214/214 [==============================] - 0s 782us/step - loss: 0.0013\n",
            "Epoch 89/100\n",
            "214/214 [==============================] - 0s 820us/step - loss: 0.0013\n",
            "Epoch 90/100\n",
            "214/214 [==============================] - 0s 792us/step - loss: 0.0013\n",
            "Epoch 91/100\n",
            "214/214 [==============================] - 0s 786us/step - loss: 0.0013\n",
            "Epoch 92/100\n",
            "214/214 [==============================] - 0s 809us/step - loss: 0.0013\n",
            "Epoch 93/100\n",
            "214/214 [==============================] - 0s 792us/step - loss: 0.0013\n",
            "Epoch 94/100\n",
            "214/214 [==============================] - 0s 772us/step - loss: 0.0013\n",
            "Epoch 95/100\n",
            "214/214 [==============================] - 0s 799us/step - loss: 0.0013\n",
            "Epoch 96/100\n",
            "214/214 [==============================] - 0s 804us/step - loss: 0.0013\n",
            "Epoch 97/100\n",
            "214/214 [==============================] - 0s 776us/step - loss: 0.0013\n",
            "Epoch 98/100\n",
            "214/214 [==============================] - 0s 782us/step - loss: 0.0012\n",
            "Epoch 99/100\n",
            "214/214 [==============================] - 0s 786us/step - loss: 0.0012\n",
            "Epoch 100/100\n",
            "214/214 [==============================] - 0s 761us/step - loss: 0.0012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCD5wd9RGnJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#classification after training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atu_R6UVGx9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEkhbpDIG7gu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7480bf72-00c1-4f1e-a72a-2b188633c57e"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)#to convert y_train into to 'one hot vector'\n",
        "y_train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(214, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkBCXnFNHHqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(10,\tinput_dim=4,\tactivation='relu'))\n",
        "\tmodel.add(Dense(8,\tactivation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8SvTDSNHQiV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6914f93-a4d8-41ef-bc2f-ebe325aa9b9f"
      },
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=1, verbose=0)\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "results = cross_val_score(estimator,X_train_tmp, y_train, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline: 48.16% (4.66%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}